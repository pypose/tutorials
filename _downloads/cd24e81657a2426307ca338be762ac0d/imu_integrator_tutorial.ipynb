{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# IMU Integrator Tutorial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uncomment this if you're using google colab to run this script\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# !pip install pypose\n# !pip install pykitti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, we will be doing IMU integration using the ``pypose.module.IMUPreintegrator`` module.\n\n## 1. What is IMU integration\nAn Inertial Measurement Unit (IMU) is a device that can measure accelaration and angular velocity. \n\nAn IMU typically consists of:\n  * Gyroscopes: providing a measure of angular velocity\n  * Accelerometers: providing a measure of acceleration\n\nWith acceleration and angular velocity, we can get velocity and position using basic kinetics:\n  * The firt integral of acceleration over time is the change in velocity.\n  * The second integral of acceleration over time is the change in position. \n\nThis process is called the IMU preintegration, often used in applications in robotics \nlike SLAM (Simultaneous Localization and Mapping).\n\n### Uncertainty\nHowever, IMU measurements contains very big noise. For example, if we put an IMU sensor in a static position,\nthe measurements will jump around zero. That's why, the more we integrate, the more uncertain we are.\nThis uncertainty can also be measured mathematically. Please refer the \n[doc](https://pypose.org/docs/main/generated/pypose.module.IMUPreintegrator/) for the math.\n\nWe will see below in a simple example, how we can get the IMU integrated position and the uncertainty\nwith ``pypose.module.IMUPreintegrator``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport argparse\nimport torch\nimport pykitti\nimport numpy as np\nimport pypose as pp\nfrom datetime import datetime\nimport torch.utils.data as Data\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Ellipse\nfrom matplotlib.collections import PatchCollection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dataset Defination\nFirst we will define the ``KITTI_IMU`` dataset as a ``data.Dataset`` in torch, for easy usage. \nWe're using the ``pykitti`` package.\nThis package provides a minimal set of tools for working with the KITTI datasets.\nTo access a data sequence, use:\n::\n\n  dataset = pykitti.raw(root, dataname, drive)\n\nSome of the data attributes we used below are:\n\n* ``dataset.timestamps``:    Timestamps are parsed into a list of datetime objects\n* ``dataset.oxts``:          List of OXTS packets and 6-dof poses as named tuples\n\nFor more details about the data format, please refer to their github page \n[here](https://github.com/utiasSTARS/pykitti#references).\n\nA sequence will be seperated into many segments. The number of segments is controlled by ``step_size``.\nEach segment of the sequence will return the measurements like ``dt``, ``acc``, and ``gyro``\nfor a few frames, defined by duration.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class KITTI_IMU(Data.Dataset):\n    def __init__(self, root, dataname, drive, duration=10, step_size=1, mode='train'):\n        super().__init__()\n        self.duration = duration\n        self.data = pykitti.raw(root, dataname, drive)\n        self.seq_len = len(self.data.timestamps) - 1\n        assert mode in ['evaluate', 'train',\n                        'test'], \"{} mode is not supported.\".format(mode)\n\n        self.dt = torch.tensor([datetime.timestamp(self.data.timestamps[i+1]) -\n                               datetime.timestamp(self.data.timestamps[i]) \n                               for i in range(self.seq_len)])\n        self.gyro = torch.tensor([[self.data.oxts[i].packet.wx, \n                                   self.data.oxts[i].packet.wy,\n                                   self.data.oxts[i].packet.wz] \n                                   for i in range(self.seq_len)])\n        self.acc = torch.tensor([[self.data.oxts[i].packet.ax, \n                                  self.data.oxts[i].packet.ay,\n                                  self.data.oxts[i].packet.az] \n                                  for i in range(self.seq_len)])\n        self.gt_rot = pp.euler2SO3(torch.tensor([[self.data.oxts[i].packet.roll, \n                                                  self.data.oxts[i].packet.pitch, \n                                                  self.data.oxts[i].packet.yaw] \n                                                  for i in range(self.seq_len)]))\n        self.gt_vel = self.gt_rot @ torch.tensor([[self.data.oxts[i].packet.vf, \n                                                   self.data.oxts[i].packet.vl, \n                                                   self.data.oxts[i].packet.vu] \n                                                   for i in range(self.seq_len)])\n        self.gt_pos = torch.tensor(\n            np.array([self.data.oxts[i].T_w_imu[0:3, 3] for i in range(self.seq_len)]))\n\n        start_frame = 0\n        end_frame = self.seq_len\n        if mode == 'train':\n            end_frame = np.floor(self.seq_len * 0.5).astype(int)\n        elif mode == 'test':\n            start_frame = np.floor(self.seq_len * 0.5).astype(int)\n\n        self.index_map = [i for i in range(\n            0, end_frame - start_frame - self.duration, step_size)]\n\n    def __len__(self):\n        return len(self.index_map)\n\n    def __getitem__(self, i):\n        frame_id = self.index_map[i]\n        end_frame_id = frame_id + self.duration\n        return {\n            'dt': self.dt[frame_id: end_frame_id],\n            'acc': self.acc[frame_id: end_frame_id],\n            'gyro': self.gyro[frame_id: end_frame_id],\n            'gyro': self.gyro[frame_id: end_frame_id],\n            'gt_pos': self.gt_pos[frame_id+1: end_frame_id+1],\n            'gt_rot': self.gt_rot[frame_id+1: end_frame_id+1],\n            'gt_vel': self.gt_vel[frame_id+1: end_frame_id+1],\n            'init_pos': self.gt_pos[frame_id][None, ...],\n            # TODO: the init rotation might be used in gravity compensation\n            'init_rot': self.gt_rot[frame_id: end_frame_id],\n            'init_vel': self.gt_vel[frame_id][None, ...],\n        }\n\n    def get_init_value(self):\n        return {'pos': self.gt_pos[:1],\n                'rot': self.gt_rot[:1],\n                'vel': self.gt_vel[:1]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Utility Functions\nThese are several utility functions. You can skip to the parameter definations\nand come back when necessary.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ``imu_collate``\n``imu_collate`` is used in batch operation, to stack data in multiple frames together.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def imu_collate(data):\n    acc = torch.stack([d['acc'] for d in data])\n    gyro = torch.stack([d['gyro'] for d in data])\n\n    gt_pos = torch.stack([d['gt_pos'] for d in data])\n    gt_rot = torch.stack([d['gt_rot'] for d in data])\n    gt_vel = torch.stack([d['gt_vel'] for d in data])\n\n    init_pos = torch.stack([d['init_pos'] for d in data])\n    init_rot = torch.stack([d['init_rot'] for d in data])\n    init_vel = torch.stack([d['init_vel'] for d in data])\n\n    dt = torch.stack([d['dt'] for d in data]).unsqueeze(-1)\n\n    return {\n        'dt': dt,\n        'acc': acc,\n        'gyro': gyro,\n\n        'gt_pos': gt_pos,\n        'gt_vel': gt_vel,\n        'gt_rot': gt_rot,\n\n        'init_pos': init_pos,\n        'init_vel': init_vel,\n        'init_rot': init_rot,\n    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ``move_to``\n``move_to`` used to move different object to CUDA device.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def move_to(obj, device):\n    if torch.is_tensor(obj):\n        return obj.to(device)\n    elif isinstance(obj, dict):\n        res = {}\n        for k, v in obj.items():\n            res[k] = move_to(v, device)\n        return res\n    elif isinstance(obj, list):\n        res = []\n        for v in obj:\n            res.append(move_to(v, device))\n        return res\n    else:\n        raise TypeError(\"Invalid type for move_to\", obj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ``plot_gaussian``\n``plot_gaussian`` used to plot an ellipse measuring uncertainty, \nbigger ellipse means bigger uncertainty.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_gaussian(ax, means, covs, color=None, sigma=3):\n    ''' Set specific color to show edges, otherwise same with facecolor.'''\n    ellipses = []\n    for i in range(len(means)):\n        eigvals, eigvecs = np.linalg.eig(covs[i])\n        axis = np.sqrt(eigvals) * sigma\n        slope = eigvecs[1][0] / eigvecs[1][1]\n        angle = 180.0 * np.arctan(slope) / np.pi\n        ellipses.append(Ellipse(means[i, 0:2], axis[0], axis[1], angle=angle))\n    ax.add_collection(PatchCollection(ellipses, edgecolors=color, linewidth=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Define Parameters\nHere we define all the parameters we will use.\nSee the help message for the usage of each parameter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser(description='IMU Preintegration')\nparser.add_argument(\"--device\",\n                    type=str,\n                    default='cpu',\n                    help=\"cuda or cpu\")\nparser.add_argument(\"--batch-size\",\n                    type=int,\n                    default=1,\n                    help=\"batch size, only support 1 now\") #why?\nparser.add_argument(\"--step-size\",\n                    type=int,\n                    default=2,\n                    help=\"the size of the integration for one interval\")\nparser.add_argument(\"--save\",\n                    type=str,\n                    default='../dataset/save/',\n                    help=\"location of png files to save\")\nparser.add_argument(\"--dataroot\",\n                    type=str,\n                    default='../dataset/',\n                    help=\"dataset location downloaded\")\nparser.add_argument(\"--dataname\",\n                    type=str,\n                    default='2011_09_26',\n                    help=\"dataset name\")\nparser.add_argument(\"--datadrive\",\n                    nargs='+',\n                    type=str,\n                    default=[\"0001\", \"0002\", \"0005\", \"0009\", \"0011\",\n                             \"0013\", \"0014\", \"0015\", \"0017\", \"0018\",\n                             \"0019\", \"0020\", \"0022\"],\n                    help=\"data sequences\")\nparser.add_argument('--plot3d',\n                    dest='plot3d',\n                    action='store_true',\n                    help=\"plot in 3D space, default: False\")\nparser.set_defaults(plot3d=False)\nargs = parser.parse_args()\nprint(args)\nos.makedirs(os.path.join(args.save), exist_ok=True)\ntorch.set_default_tensor_type(torch.DoubleTensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Perform Integration\nWith everything set up, we will perform the core operation of IMU integration.\nThere are mainly 5 steps in the codes below:\n\n  #. **Step 1**: Define dataloader using the ``KITTI_IMU`` class we defined above\n  #. **Step 2**: Get the initial position, rotation and velocity, all 0 here\n  #. **Step 3**: Define the IMUPreintegrator\n  #. **Step 4**: Perform integration: \n                 After running the forward function of the ``integrator``, the result is stored in ``state``,\n                 where ``state['pos']`` is the integrated position, and ``state['cov']`` is the uncertainty measurements.\n\n                 Note that ``state['cov']`` is a 9x9 matrix in the order of rotation, velocity, and position. \n                 That's why in visualization we are using ``covs[:, 6:8, 6:8]`` here: they are the covariance matrix of ``x`` and ``y`` position.\n  #. **Step 5**: Visualization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for drive in args.datadrive:\n\n    # Step 1: Define dataloader using the ``KITTI_IMU`` class we defined above\n    dataset = KITTI_IMU(args.dataroot,\n                        args.dataname,\n                        drive,\n                        duration=args.step_size,\n                        step_size=args.step_size,\n                        mode='evaluate')\n    loader = Data.DataLoader(dataset=dataset,\n                             batch_size=args.batch_size,\n                             collate_fn=imu_collate,\n                             shuffle=False)\n\n    # Step 2: Get the initial position, rotation and velocity, all 0 here\n    init = dataset.get_init_value()\n\n    # Step 3: Define the IMUPreintegrator.\n    integrator = pp.module.IMUPreintegrator(init['pos'],\n                                            init['rot'],\n                                            init['vel'],\n                                            reset=False).to(args.device)\n\n    # Step 4: Perform integration\n    poses, poses_gt = [init['pos']], [init['pos']]\n    covs = [torch.zeros(9, 9)]\n\n    for idx, data in enumerate(loader):\n        data = move_to(data, args.device)\n        state = integrator(dt=data['dt'],\n                           gyro=data['gyro'],\n                           acc=data['acc'],\n                           rot=data['init_rot'])\n        poses_gt.append(data['gt_pos'][..., -1, :].cpu())\n        poses.append(state['pos'][..., -1, :].cpu())\n        covs.append(state['cov'][..., -1, :, :].cpu())\n\n    poses = torch.cat(poses).numpy()\n    poses_gt = torch.cat(poses_gt).numpy()\n    covs = torch.stack(covs, dim=0).numpy()\n\n    # Step 5: Visualization\n    plt.figure(figsize=(5, 5))\n    if args.plot3d:\n        ax = plt.axes(projection='3d')\n        ax.plot3D(poses[:, 0], poses[:, 1], poses[:, 2], 'b')\n        ax.plot3D(poses_gt[:, 0], poses_gt[:, 1], poses_gt[:, 2], 'r')\n    else:\n        ax = plt.axes()\n        ax.plot(poses[:, 0], poses[:, 1], 'b')\n        ax.plot(poses_gt[:, 0], poses_gt[:, 1], 'r')\n        plot_gaussian(ax, poses[:, 0:2], covs[:, 6:8, 6:8])\n    plt.title(\"PyPose IMU Integrator\")\n    plt.legend([\"PyPose\", \"Ground Truth\"])\n    figure = os.path.join(args.save, args.dataname+'_'+drive+'.png')\n    plt.savefig(figure)\n    print(\"Saved to\", figure)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that, in some of the sequences,  \nthe integrated position drifts away from the groundtruth, also the uncertainty grows very big.\nThis shows the noisy nature of the IMU sensor. \nIn the IMUCorrector tutorial, we will see an example of how we can correct this.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}