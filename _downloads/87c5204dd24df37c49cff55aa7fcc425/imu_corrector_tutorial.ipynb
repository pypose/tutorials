{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# IMU Corrector Tutorial\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport pypose as pp\nfrom torch import nn\nimport tqdm, argparse\nimport torch.utils.data as Data\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom imu_dataset_tutorial import KITTI_IMU, imu_collate, move_to"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define IMU Corrector\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class IMUCorrector(nn.Module):\n    def __init__(self, size_list= [6, 64, 128, 128, 128, 6]):\n        super().__init__()\n        layers = []\n        self.size_list = size_list\n        for i in range(len(size_list) - 2):\n            layers.append(nn.Linear(size_list[i],size_list[i+1]))\n            layers.append(nn.GELU())\n        layers.append(nn.Linear(size_list[-2], size_list[-1]))\n        self.net = nn.Sequential(*layers)\n        self.imu = pp.module.IMUPreintegrator(reset=True, prop_cov=False)\n\n    def forward(self, data, init_state):\n        feature = torch.cat([data[\"acc\"], data[\"gyro\"]], dim = -1)\n        B, F = feature.shape[:2]\n\n        output = self.net(feature.reshape(B*F,6)).reshape(B, F, 6)\n        corrected_acc = output[...,:3] + data[\"acc\"]\n        corrected_gyro = output[...,3:] + data[\"gyro\"]\n\n        return self.imu(init_state = init_state, dt = data['dt'], gyro = corrected_gyro,\n            acc = corrected_acc, rot = data['gt_rot'].contiguous())\n\n\ndef get_loss(inte_state, data):\n    pos_loss = torch.nn.functional.mse_loss(inte_state['pos'][:,-1,:], data['gt_pos'][:,-1,:])\n    rot_loss = (data['gt_rot'][:,-1,:] * inte_state['rot'][:,-1,:].Inv()).Log().norm()\n\n    loss = pos_loss + rot_loss\n    return loss, {'pos_loss': pos_loss, 'rot_loss': rot_loss}\n\n\ndef train(network, train_loader, epoch, optimizer, device=\"cuda:0\"):\n    \"\"\"\n    Train network for one epoch using a specified data loader\n    Outputs all targets, predicts, predicted covariance params, and losses in numpy arrays\n    \"\"\"\n    network.train()\n    running_loss = 0\n    t_range = tqdm.tqdm(train_loader)\n    for i, data in enumerate(t_range):\n        data = move_to(data, device)\n        init_state = {\n            \"pos\": data['init_pos'], \n            \"rot\": data['init_rot'][:,:1,:],\n            \"vel\": data['init_vel'],}\n        state = network(data, init_state)\n\n        losses, _ = get_loss(state, data)\n        running_loss += losses.item()\n\n        t_range.set_description(f'iteration: {i:04d}, losses: {losses:.06f}')\n        t_range.refresh()\n        losses.backward()\n        optimizer.step()\n\n    return (running_loss/i)\n\n\ndef test(network, loader, device = \"cuda:0\"):\n    network.eval()\n    with torch.no_grad():\n        running_loss = 0\n        for i, data in enumerate(tqdm.tqdm(loader)):\n            data = move_to(data, device)\n            init_state = {\n            \"pos\": data['init_pos'], \n            \"rot\": data['init_rot'][:,:1,:],\n            \"vel\": data['init_vel'],}\n            state = network(data, init_state)\n\n            losses, _ = get_loss(state, data)\n            running_loss += losses.item()\n\n        print(\"the running loss of the test set %0.6f\"%(running_loss/i))\n\n    return (running_loss/i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define Datasets\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser()\nparser.add_argument(\"--device\", type=str, default='cuda:0', help=\"cuda or cpu\")\nparser.add_argument(\"--batch-size\", type=int, default=4, help=\"batch size\")\nparser.add_argument(\"--max_epoches\", type=int, default=100, help=\"max_epoches\")\nparser.add_argument(\"--dataroot\", type=str, default='../dataset', help=\"dataset location downloaded\")\nparser.add_argument(\"--dataname\", type=str, default='2011_09_26', help=\"dataset name\")\nparser.add_argument(\"--datadrive\", nargs='+', type=str, default=[ \"0001\"], help=\"data sequences\")\nparser.add_argument('--load_ckpt', default=False, action=\"store_true\")\nargs = parser.parse_args(); print(args)\n\ntrain_dataset = KITTI_IMU(args.dataroot, args.dataname, args.datadrive[0], duration=10, mode='train')\ntest_dataset = KITTI_IMU(args.dataroot, args.dataname, args.datadrive[0],  duration=10, mode='test')\ntrain_loader = Data.DataLoader(dataset=train_dataset, batch_size=args.batch_size, collate_fn=imu_collate, shuffle=True)\ntest_loader = Data.DataLoader(dataset=test_dataset, batch_size=args.batch_size, collate_fn=imu_collate, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optimizer\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "network = IMUCorrector().to(args.device)\noptimizer = torch.optim.Adam(network.parameters(), lr = 5e-6)  # to use with ViTs\nscheduler = ReduceLROnPlateau(optimizer, 'min', factor = 0.1, patience = 10)# default setup\n\nfor epoch_i in range(args.max_epoches):\n    train_loss = train(network, train_loader, epoch_i, optimizer, device = args.device)\n    test_loss = test(network, test_loader, device = args.device)\n    scheduler.step(train_loss)\n    print(\"train loss: %f test loss: %f \"%(train_loss, test_loss))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}