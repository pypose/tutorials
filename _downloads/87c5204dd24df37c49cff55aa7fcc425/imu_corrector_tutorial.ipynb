{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# IMU Corrector Tutorial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uncomment this if you're using google colab to run this script\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# !pip install pypose\n# !pip install pykitti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, we will be implementing a simple IMUCorrector\nusing ``torch.nn`` modules and ``pypose.IMUPreintegrator``.\nThe functionality of our ``IMUCorrector`` is to take an input noisy IMU sensor reading,\nand output the corrected IMU integration result. \nIn some way, ``IMUCorrector`` is an improved ``IMUPreintegrator``.\n\nWe will show that, we can combine ``pypose.module.IMUPreintegrator`` into network training smoothly.\n\n**Skip the first two part if you have seen it in the imu integrator tutorial**\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport pykitti\nimport numpy as np\nimport pypose as pp\nfrom torch import nn\nimport tqdm, argparse\nfrom datetime import datetime\nimport torch.utils.data as Data\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Ellipse\nfrom matplotlib.collections import PatchCollection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Defination\nFirst we will define the ``KITTI_IMU`` dataset as a ``data.Dataset`` in torch, for easy usage. \nWe're using the ``pykitti`` package.\nThis package provides a minimal set of tools for working with the KITTI datasets.\nTo access a data sequence, use:\n::\n\n  dataset = pykitti.raw(root, dataname, drive)\n\nSome of the data attributes we used below are:\n\n* ``dataset.timestamps``:    Timestamps are parsed into a list of datetime objects\n* ``dataset.oxts``:          List of OXTS packets and 6-dof poses as named tuples\n\nFor more details about the data format, please refer to their github page \n[here](https://github.com/utiasSTARS/pykitti#references).\n\nA sequence will be seperated into many segments. The number of segments is controlled by ``step_size``.\nEach segment of the sequence will return the measurements like ``dt``, ``acc``, and ``gyro``\nfor a few frames, defined by duration.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class KITTI_IMU(Data.Dataset):\n    def __init__(self, root, dataname, drive, duration=10, step_size=1, mode='train'):\n        super().__init__()\n        self.duration = duration\n        self.data = pykitti.raw(root, dataname, drive)\n        self.seq_len = len(self.data.timestamps) - 1\n        assert mode in ['evaluate', 'train',\n                        'test'], \"{} mode is not supported.\".format(mode)\n\n        self.dt = torch.tensor([datetime.timestamp(self.data.timestamps[i+1]) -\n                               datetime.timestamp(self.data.timestamps[i]) \n                               for i in range(self.seq_len)])\n        self.gyro = torch.tensor([[self.data.oxts[i].packet.wx, \n                                   self.data.oxts[i].packet.wy,\n                                   self.data.oxts[i].packet.wz] \n                                   for i in range(self.seq_len)])\n        self.acc = torch.tensor([[self.data.oxts[i].packet.ax, \n                                  self.data.oxts[i].packet.ay,\n                                  self.data.oxts[i].packet.az] \n                                  for i in range(self.seq_len)])\n        self.gt_rot = pp.euler2SO3(torch.tensor([[self.data.oxts[i].packet.roll, \n                                                  self.data.oxts[i].packet.pitch, \n                                                  self.data.oxts[i].packet.yaw] \n                                                  for i in range(self.seq_len)]))\n        self.gt_vel = self.gt_rot @ torch.tensor([[self.data.oxts[i].packet.vf, \n                                                   self.data.oxts[i].packet.vl, \n                                                   self.data.oxts[i].packet.vu] \n                                                   for i in range(self.seq_len)])\n        self.gt_pos = torch.tensor(\n            np.array([self.data.oxts[i].T_w_imu[0:3, 3] for i in range(self.seq_len)]))\n\n        start_frame = 0\n        end_frame = self.seq_len\n        if mode == 'train':\n            end_frame = np.floor(self.seq_len * 0.5).astype(int)\n        elif mode == 'test':\n            start_frame = np.floor(self.seq_len * 0.5).astype(int)\n\n        self.index_map = [i for i in range(\n            0, end_frame - start_frame - self.duration, step_size)]\n\n    def __len__(self):\n        return len(self.index_map)\n\n    def __getitem__(self, i):\n        frame_id = self.index_map[i]\n        end_frame_id = frame_id + self.duration\n        return {\n            'dt': self.dt[frame_id: end_frame_id],\n            'acc': self.acc[frame_id: end_frame_id],\n            'gyro': self.gyro[frame_id: end_frame_id],\n            'gyro': self.gyro[frame_id: end_frame_id],\n            'gt_pos': self.gt_pos[frame_id+1: end_frame_id+1],\n            'gt_rot': self.gt_rot[frame_id+1: end_frame_id+1],\n            'gt_vel': self.gt_vel[frame_id+1: end_frame_id+1],\n            'init_pos': self.gt_pos[frame_id][None, ...],\n            # TODO: the init rotation might be used in gravity compensation\n            'init_rot': self.gt_rot[frame_id: end_frame_id],\n            'init_vel': self.gt_vel[frame_id][None, ...],\n        }\n\n    def get_init_value(self):\n        return {'pos': self.gt_pos[:1],\n                'rot': self.gt_rot[:1],\n                'vel': self.gt_vel[:1]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Utility Functions\nThese are several utility functions. You can skip to the parameter definations\nand come back when necessary.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ``imu_collate``\n``imu_collate`` is used in batch operation, to stack data in multiple frames together.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def imu_collate(data):\n    acc = torch.stack([d['acc'] for d in data])\n    gyro = torch.stack([d['gyro'] for d in data])\n\n    gt_pos = torch.stack([d['gt_pos'] for d in data])\n    gt_rot = torch.stack([d['gt_rot'] for d in data])\n    gt_vel = torch.stack([d['gt_vel'] for d in data])\n\n    init_pos = torch.stack([d['init_pos'] for d in data])\n    init_rot = torch.stack([d['init_rot'] for d in data])\n    init_vel = torch.stack([d['init_vel'] for d in data])\n\n    dt = torch.stack([d['dt'] for d in data]).unsqueeze(-1)\n\n    return {\n        'dt': dt,\n        'acc': acc,\n        'gyro': gyro,\n\n        'gt_pos': gt_pos,\n        'gt_vel': gt_vel,\n        'gt_rot': gt_rot,\n\n        'init_pos': init_pos,\n        'init_vel': init_vel,\n        'init_rot': init_rot,\n    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ``move_to``\n``move_to`` used to move different object to CUDA device.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def move_to(obj, device):\n    if torch.is_tensor(obj):\n        return obj.to(device)\n    elif isinstance(obj, dict):\n        res = {}\n        for k, v in obj.items():\n            res[k] = move_to(v, device)\n        return res\n    elif isinstance(obj, list):\n        res = []\n        for v in obj:\n            res.append(move_to(v, device))\n        return res\n    else:\n        raise TypeError(\"Invalid type for move_to\", obj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ``plot_gaussian``\n``plot_gaussian`` used to plot an ellipse measuring uncertainty, \nbigger ellipse means bigger uncertainty.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_gaussian(ax, means, covs, color=None, sigma=3):\n    ''' Set specific color to show edges, otherwise same with facecolor.'''\n    ellipses = []\n    for i in range(len(means)):\n        eigvals, eigvecs = np.linalg.eig(covs[i])\n        axis = np.sqrt(eigvals) * sigma\n        slope = eigvecs[1][0] / eigvecs[1][1]\n        angle = 180.0 * np.arctan(slope) / np.pi\n        ellipses.append(Ellipse(means[i, 0:2], axis[0], axis[1], angle=angle))\n    ax.add_collection(PatchCollection(ellipses, edgecolors=color, linewidth=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Define IMU Corrector\nHere we define the ``IMUCorrecter`` module. It has two parts, the ``net`` and the ``imu``,\n  * ``net`` is a network that resemble an autoencoder. \n    It consists of a sequence of linear layer and activation layer.\n    It will return the IMU measurements correction. Add this correction to the original IMU sensor data,\n    we will get the corrected sensor reading.\n  * ``imu`` is a ``pypose.module.IMUPreintegrator``. Use the corrected sensor reading from previous step as \n    the input to the ``IMUPreintegrator``, we can get a more accurate IMU integration result.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class IMUCorrector(nn.Module):\n    def __init__(self, size_list= [6, 64, 128, 128, 128, 6]):\n        super().__init__()\n        layers = []\n        self.size_list = size_list\n        for i in range(len(size_list) - 2):\n            layers.append(nn.Linear(size_list[i], size_list[i+1]))\n            layers.append(nn.GELU())\n        layers.append(nn.Linear(size_list[-2], size_list[-1]))\n        self.net = nn.Sequential(*layers)\n        self.imu = pp.module.IMUPreintegrator(reset=True, prop_cov=False)\n\n    def forward(self, data, init_state):\n        feature = torch.cat([data[\"acc\"], data[\"gyro\"]], dim = -1)\n        B, F = feature.shape[:2]\n\n        output = self.net(feature.reshape(B*F,6)).reshape(B, F, 6)\n        corrected_acc = output[...,:3] + data[\"acc\"]\n        corrected_gyro = output[...,3:] + data[\"gyro\"]\n\n        return self.imu(init_state = init_state, \n                        dt = data['dt'], \n                        gyro = corrected_gyro, \n                        acc = corrected_acc, \n                        rot = data['gt_rot'].contiguous())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Define the Loss Function\nThe loss function consists of two parts: position loss and rotation loss.\n\nFor position loss, we used ``torch.nn.functional.mse_loss``, which is the mean squared error.\nSee the [docs](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html)\nfor more detail.\n\nFor rotation loss, we first compute pose error between the output rotation and the ground truth rotation, \nthen taking the norm of the lie algebra of the pose error.\n\nFinally, we add the two loss together as our combined loss.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_loss(inte_state, data):\n    pos_loss = torch.nn.functional.mse_loss(inte_state['pos'][:,-1,:], data['gt_pos'][:,-1,:])\n    rot_loss = (data['gt_rot'][:,-1,:] * inte_state['rot'][:,-1,:].Inv()).Log().norm()\n\n    loss = pos_loss + rot_loss\n    return loss, {'pos_loss': pos_loss, 'rot_loss': rot_loss}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Define the Training Process\nThis is the training process, which has three steps:\n  #. **Step 1**: Run forward function, to get the current network output\n  #. **Step 2**: Collect loss, for doing backward in **Step 3**\n  #. **Step 3**: Get gradients and do optimization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train(network, train_loader, epoch, optimizer, device=\"cuda:0\"):\n    \"\"\"\n    Train network for one epoch using a specified data loader\n    Outputs all targets, predicts, predicted covariance params, and losses in numpy arrays\n    \"\"\"\n    network.train()\n    running_loss = 0\n    t_range = tqdm.tqdm(train_loader)\n    for i, data in enumerate(t_range):\n\n        # Step 1: Run forward function\n        data = move_to(data, device)\n        init_state = {\n            \"pos\": data['init_pos'], \n            \"rot\": data['init_rot'][:,:1,:],\n            \"vel\": data['init_vel'],}\n        state = network(data, init_state)\n\n        # Step 2: Collect loss\n        losses, _ = get_loss(state, data)\n        running_loss += losses.item()\n\n        # Step 3: Get gradients and do optimization\n        t_range.set_description(f'iteration: {i:04d}, losses: {losses:.06f}')\n        t_range.refresh()\n        losses.backward()\n        optimizer.step()\n\n    return (running_loss/i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Define the Testing Process\nThis is the testing process, which has two steps:\n  #. **Step 1**: Run forward function, to get the current network output\n  #. **Step 2**: Collect loss, to evaluate the network performance\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def test(network, loader, device = \"cuda:0\"):\n    network.eval()\n    with torch.no_grad():\n        running_loss = 0\n        for i, data in enumerate(tqdm.tqdm(loader)):\n\n            # Step 1: Run forward function\n            data = move_to(data, device)\n            init_state = {\n            \"pos\": data['init_pos'], \n            \"rot\": data['init_rot'][:,:1,:],\n            \"vel\": data['init_vel'],}\n            state = network(data, init_state)\n\n            # Step 2: Collect loss\n            losses, _ = get_loss(state, data)\n            running_loss += losses.item()\n\n        print(\"the running loss of the test set %0.6f\"%(running_loss/i))\n\n    return (running_loss/i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Define Parameters\nHere we define all the parameters we will use.\nSee the help message for the usage of each parameter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser()\nparser.add_argument(\"--device\", \n                    type=str, \n                    default='cuda:0', \n                    help=\"cuda or cpu\")\nparser.add_argument(\"--batch-size\", \n                    type=int, \n                    default=4, \n                    help=\"batch size\")\nparser.add_argument(\"--max_epoches\", \n                    type=int, \n                    default=100, \n                    help=\"max_epoches\")\nparser.add_argument(\"--dataroot\", \n                    type=str, \n                    default='../dataset', \n                    help=\"dataset location downloaded\")\nparser.add_argument(\"--dataname\", \n                    type=str, \n                    default='2011_09_26', \n                    help=\"dataset name\")\nparser.add_argument(\"--datadrive\", \n                    nargs='+', \n                    type=str, \n                    default=[ \"0001\"], \n                    help=\"data sequences\")\nparser.add_argument('--load_ckpt', \n                    default=False, \n                    action=\"store_true\")\nargs, unknown = parser.parse_known_args(); print(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Define Dataloaders\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_dataset = KITTI_IMU(args.dataroot, args.dataname, args.datadrive[0], \n                          duration=10, mode='train')\ntest_dataset = KITTI_IMU(args.dataroot, args.dataname, args.datadrive[0], \n                         duration=10, mode='test')\ntrain_loader = Data.DataLoader(dataset=train_dataset, batch_size=args.batch_size, \n                               collate_fn=imu_collate, shuffle=True)\ntest_loader = Data.DataLoader(dataset=test_dataset, batch_size=args.batch_size,\n                              collate_fn=imu_collate, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Main Training Loop\nHere we will run our main training loop. \nFirst, like in pytorch, we will define the network, optimizer and scheduler.\n\nIf you are not familiar with the process of training a network,\nwe would recommand you reading one of the PyTorch tutorial, like \n[this](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html).\n\nFor each epoch, we run both the training and testing once and collect the running loss.\nWe can see from the output message below: the running losss is reducing,\nwhich means our IMUCorrecter is working. \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "network = IMUCorrector().to(args.device)\noptimizer = torch.optim.Adam(network.parameters(), lr = 5e-6)  # to use with ViTs\nscheduler = ReduceLROnPlateau(optimizer, 'min', factor = 0.1, patience = 10) # default setup\n\nfor epoch_i in range(args.max_epoches):\n    train_loss = train(network, train_loader, epoch_i, optimizer, device = args.device)\n    test_loss = test(network, test_loader, device = args.device)\n    scheduler.step(train_loss)\n    print(\"train loss: %f test loss: %f \"%(train_loss, test_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And that's it. We'are done with our IMUCorrecter tutorials. Thanks for reading. \n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}