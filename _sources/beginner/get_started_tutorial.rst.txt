
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/get_started_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_get_started_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_get_started_tutorial.py:


Get Started Tutorial
==================

.. GENERATED FROM PYTHON SOURCE LINES 8-10

Uncomment this if you're using google colab to run this script


.. GENERATED FROM PYTHON SOURCE LINES 10-14

.. code-block:: default


    # !pip install pypose 









.. GENERATED FROM PYTHON SOURCE LINES 20-25

Sample Code of LieTensor
---------------------------------------
The following code sample shows how to rotate random 
points and compute the gradient of batched rotation.


.. GENERATED FROM PYTHON SOURCE LINES 25-30

.. code-block:: default


    import torch
    import pypose as pp









.. GENERATED FROM PYTHON SOURCE LINES 31-33

Create a random so(3) LieTensor


.. GENERATED FROM PYTHON SOURCE LINES 33-38

.. code-block:: default


    r = pp.randn_so3(2, requires_grad=True)
    print(r)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    so3Type LieTensor:
    LieTensor([[ 0.2227, -0.3219, -0.3363],
               [-0.6982, -0.3682, -0.3169]], requires_grad=True)




.. GENERATED FROM PYTHON SOURCE LINES 39-41

Get the Lie Group of the Lie Algebra


.. GENERATED FROM PYTHON SOURCE LINES 41-46

.. code-block:: default


    R = r.Exp() # Equivalent to: R = pp.Exp(r)
    print(R)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    SO3Type LieTensor:
    LieTensor([[ 0.1101, -0.1592, -0.1663,  0.9669],
               [-0.3387, -0.1786, -0.1537,  0.9109]], grad_fn=<AliasBackward0>)




.. GENERATED FROM PYTHON SOURCE LINES 47-49

Create a random point and rotate it based on the Lie Group rotation tensor


.. GENERATED FROM PYTHON SOURCE LINES 49-54

.. code-block:: default


    p = R @ torch.randn(3) # Rotate random point
    print(p)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    tensor([[-0.6147, -1.4090,  1.9762],
            [-0.4468,  0.7588,  2.3438]], grad_fn=<ViewBackward0>)




.. GENERATED FROM PYTHON SOURCE LINES 55-57

Compute the gradient and print it


.. GENERATED FROM PYTHON SOURCE LINES 57-62

.. code-block:: default


    p.sum().backward() # Compute gradient
    r.grad # Print gradient






.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    tensor([[-3.6060,  2.1054,  1.1129],
            [-2.0774,  2.5985,  0.1027]])



.. GENERATED FROM PYTHON SOURCE LINES 63-69

Sample code of optimizer
---------------------------------------------
We show how to estimate batched transform inverse by a
2nd-order optimizer. Two usage options for a scheduler
are provided, each of which can work independently.


.. GENERATED FROM PYTHON SOURCE LINES 69-109

.. code-block:: default


    from torch import nn
    import torch, pypose as pp
    from pypose.optim import LM
    from pypose.optim.strategy import Constant
    from pypose.optim.scheduler import StopOnPlateau

    class InvNet(nn.Module):

        def __init__(self, *dim):
            super().__init__()
            init = pp.randn_SE3(*dim)
            self.pose = pp.Parameter(init)

        def forward(self, input):
            error = (self.pose @ input).Log()
            return error.tensor()
    
    device = torch.device("cuda")
    input = pp.randn_SE3(2, 2, device=device)
    invnet = InvNet(2, 2).to(device)
    strategy = Constant(damping=1e-4)
    optimizer = LM(invnet, strategy=strategy)
    scheduler = StopOnPlateau(optimizer,
                              steps=10,
                              patience=3,
                              decreasing=1e-3,
                              verbose=True)

    # 1st option, full optimization
    scheduler.optimize(input=input)

    # 2nd option, step optimization
    while scheduler.continual():
        loss = optimizer.step(input)
        scheduler.step(loss)







.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    StopOnPlateau on step 0 Loss 3.491947e+01 --> Loss 1.963101e-06 (reduction/loss: 1.0000e+00).
    StopOnPlateau on step 1 Loss 1.963101e-06 --> Loss 1.194070e-13 (reduction/loss: 1.0000e+00).
    StopOnPlateau on step 2 Loss 1.194070e-13 --> Loss 1.065370e-13 (reduction/loss: 1.0778e-01).
    StopOnPlateau on step 3 Loss 1.065370e-13 --> Loss 5.321509e-17 (reduction/loss: 9.9950e-01).
    StopOnPlateau: Maximum patience steps reached, Quiting..




.. GENERATED FROM PYTHON SOURCE LINES 110-115

And then we are finished with the two sample codes mentioned in our paper.

Now you may be free to explore other tutorials. 
See How PyPose can be utilized in real robotics applications.



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  1.828 seconds)


.. _sphx_glr_download_beginner_get_started_tutorial.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: get_started_tutorial.py <get_started_tutorial.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: get_started_tutorial.ipynb <get_started_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
